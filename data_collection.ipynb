{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = '---'\n",
    "consumer_secret = '---'\n",
    "access_token = '---'\n",
    "access_secret = '---'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['id', 'text','preprocessed', 'sentiment']\n",
    "header1 = ['id', 'text', 'created_at', 'location', 'favorite_count', 'retweet_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = open('tweets_all.csv', 'w', encoding='UTF8')\n",
    "writer1 = csv.writer(f1)\n",
    "writer1.writerow(header1)\n",
    "f = open('tweets.csv', 'w', encoding='UTF8')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweet():\n",
    "    try:\n",
    "        auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "        auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "        api = tweepy.API(auth)\n",
    "        \n",
    "        query = 'pandemia'\n",
    "        language = 'pt'\n",
    "        since = '2020-05-01'\n",
    "        max_id = -1\n",
    "        maxTweets = 1000\n",
    "        sinceId = None\n",
    "        tweetCount = 0\n",
    "        print(\"def:\", api.rate_limit_status()['resources']['application']['/application/rate_limit_status']['remaining'])\n",
    "        while tweetCount < maxTweets:\n",
    "            try:\n",
    "                if (max_id <= 0):\n",
    "                    if (not sinceId):\n",
    "                        results = api.search(q = query, lang = language, since = since, result_type = 'recent', count = 100, tweet_mode = 'extended')\n",
    "                    else:\n",
    "                        results = api.search(q = query, lang = language, since = since, result_type = 'recent', count = 100, \n",
    "                                            tweet_mode = 'extended', since_id=sinceId)\n",
    "                else:\n",
    "                    if (not sinceId):\n",
    "                        results = api.search(q = query, lang = language, since = since, result_type = 'recent', count = 100, \n",
    "                                            tweet_mode = 'extended', max_id=str(max_id - 1))\n",
    "                    else:\n",
    "                        results = api.search(q = query, lang = language, since = since, result_type = 'recent', count = 100, \n",
    "                                            tweet_mode = 'extended', max_id=str(max_id - 1), since_id=sinceId)\n",
    "                if not results:\n",
    "                    break\n",
    "                    \n",
    "                for tweet in results:\n",
    "                    if not tweet.full_text.startswith(\"RT\"):\n",
    "                        data = [tweet.id, tweet.full_text]\n",
    "                        writer.writerow(data)\n",
    "                        data1 = [tweet.id, tweet.full_text, tweet.created_at, tweet.favorite_count, tweet.retweet_count, tweet.user.location]\n",
    "                        writer1.writerow(data1)\n",
    "                        tweetCount += 1\n",
    "                        if tweetCount ==1000:\n",
    "                            break\n",
    "                        \n",
    "                \n",
    "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "                max_id = results[-1].id\n",
    "            except tweepy.TweepError as e:\n",
    "                print(\"some error : \" + str(e))\n",
    "                break\n",
    "    except tweepy.error.TweepError as e:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def: 180\n",
      "Downloaded 38 tweets\n",
      "Downloaded 71 tweets\n",
      "Downloaded 103 tweets\n",
      "Downloaded 145 tweets\n",
      "Downloaded 183 tweets\n",
      "Downloaded 220 tweets\n",
      "Downloaded 264 tweets\n",
      "Downloaded 304 tweets\n",
      "Downloaded 337 tweets\n",
      "Downloaded 370 tweets\n",
      "Downloaded 400 tweets\n",
      "Downloaded 431 tweets\n",
      "Downloaded 467 tweets\n",
      "Downloaded 505 tweets\n",
      "Downloaded 541 tweets\n",
      "Downloaded 575 tweets\n",
      "Downloaded 604 tweets\n",
      "Downloaded 649 tweets\n",
      "Downloaded 685 tweets\n",
      "Downloaded 726 tweets\n",
      "Downloaded 761 tweets\n",
      "Downloaded 806 tweets\n",
      "Downloaded 836 tweets\n",
      "Downloaded 867 tweets\n",
      "Downloaded 899 tweets\n",
      "Downloaded 930 tweets\n",
      "Downloaded 977 tweets\n",
      "Downloaded 1000 tweets\n"
     ]
    }
   ],
   "source": [
    "extract_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1.close() \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
